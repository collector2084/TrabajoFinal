{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e7ea21-6437-48e8-a9e4-3bdc05f709c9",
   "metadata": {},
   "source": [
    "# Analisis de texto en Python: Preprocesamiento\n",
    "\n",
    "* * * \n",
    "\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "### Objetivos de aprendizaje \n",
    "    \n",
    "* Aprender pasos comunes para preprocesamiento de datos de texto, tan bien como especificar operaciones para preprocesamiento de datos de Twitter.\n",
    "* Conocer los paquetes NPL comunmente usado y acoplarlos.\n",
    "* Entender tokenizadores, y como cambiar desde la llegada de los grandes modelos de lenguaje.\n",
    "</div>\n",
    "\n",
    "### Icons Used in This Notebook\n",
    "🔔 **Pregunta**: Una pregunta rapida para ayudar a entender que esta sucediendo.<br>\n",
    "🥊 **Reto**: Ejercicios interactivos. Trabajaremos a traves de esto en el taller!<br>\n",
    "⚠️ **Advertencia:** Aviso sobre cosas complicadas o errores comunes.<br>\n",
    "🎬 **Demo**: Mostrando algo más avanzado: para que sepas para qué se puede usar Python!<br> \n",
    "\n",
    "### Secciones\n",
    "1. [Preprocessing](#section1)\n",
    "2. [Tokenization](#section2)\n",
    "\n",
    "En esta seccion de tres parte del taller, aprenderemos la construccion de bloques para ejecutar anlisis de texto en Python. Estas tecnicas se encuentran en el dominio de Procesamiento de Lenguaje Natural (NLP). NLP es un campo que se ocupa con identificacion y extrayendo patrones de lenguaje, ante todo escribiendo textos. A lo largo de la serie de talleres, interactuaremos con paquetes para ejecutar analisis de texto: empezando desde metodos de cadena simple hasta paquetes especificos  NLP, tal como `nltk`, `spaCy`, y mas recientes sobre Modelos de Lenguaje Grande (`BERT`).\n",
    "\n",
    "Ahora, Instalemos estos paquetes correctamente ante de introducirnos en la materia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d442e4c7-e926-493d-a64e-516616ad915a",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Uncomment the following lines to install packages/model\n",
    "# %pip install NLTK\n",
    "# %pip install transformers\n",
    "# %pip install spaCy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b8f8e-4e69-426e-a202-ec48b325e89a",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "\n",
    "# Preprocesamiento\n",
    "\n",
    "En la parte 1 de este taller, Direccionaremos el primer paso de analisis de texto. Nuestra meta es convertir la fila, datos de texto desordenados en un formato consistente. Este proceso es a menudo llamado **preprocesamiento**, **limpieza de texto**, o **normalización de texto**.\n",
    "\n",
    "Notaras que al final del procesamiento,nuestro sto es aun en formato que nosostros podemos leer y entender. En la parte 2 y 3, comenzaremos nuestra incursión en la conversión de datos de texto en una representación numérica, un formato que las computadoras pueden manejar más fácilmente. \n",
    "\n",
    "🔔 **Pregunta**: Vamos a pausar un momento para reflexionar sobre **sus** previas experiencias trabajando sobre texto de datos. \n",
    "- Cual es el formato de los datos de texto con los que has interactuado (plain text, CSV, or XML)?\n",
    "- De donde viene (structured corpus, scraped from the web, survey data)?\n",
    "- Esta desordenado (i.e., is the data formatted consistently)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35911a-3b3f-4a48-a7d1-9882aab04851",
   "metadata": {},
   "source": [
    "## Procesos Comunes\n",
    "\n",
    "Preprocesamiento no es aldo que podamos lograr con una simple linea de código. Nosotros a menudo empezamos por familiarizarnos nosotros mismo con los datos, y en el camino, obtenemos una comprensión más clara de la granularidad del preprocesamiento que queremos aplicar.\n",
    "\n",
    "Inicialmente, comenzamos aplicando un conjunto de procesos comúnmente utilizados para limpiar los datos. Estas operaciones so alteran facilmente la forma o el significado de los datos; sirven como un procedimiento estandarizado para remodelar los datos en un formato consistente.\n",
    "\n",
    "La siguientes procesos, por ejemplo, son comunmente aplicados para procesos de textos en ingles de varios generos. Estas operaciones pueden  estar siendo usadas para funciones integrles en Python, tal como metodos`string`, y expresiones regulares. \n",
    "- El texto en minuscula\n",
    "- Remover puntuaciones marcadas \n",
    "- Remover caracteres de espacio en blanco\n",
    "- Remover palabras en stop \n",
    "\n",
    "Después al iniciar el procesamiento, nosotros debemos cambiar para realizar procesos de tareas especificas, cuyos detalles a menudo dependen de la tarea posterior que queremos realizar y de la naturaleza de los datos de texto (i.e., its stylistic and linguistic features).  \n",
    "\n",
    "Antes de adentrarnos en estas operaciones, echemos un vistazo a nuestros datos!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5d7350-9a1e-4db9-b828-a87fe1676d8d",
   "metadata": {},
   "source": [
    "### Importar el texto de datos\n",
    "\n",
    "El texto de datos, podemos estar trabajando con un archivo CSV. Contiene tuits sobre aerolíneas estadounidenses, eliminados desde febrero de 2015. \n",
    "\n",
    "Vamos a leer el archivo `airline_tweets.csv` dentro del dataframe con `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7228677e-001b-4484-b85d-9d4218a1469d",
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pandas\n",
      "Version: 2.2.2\n",
      "Summary: Powerful data structures for data analysis, time series, and statistics\n",
      "Home-page: https://pandas.pydata.org\n",
      "Author: \n",
      "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
      "License: BSD 3-Clause License\n",
      "\n",
      "Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
      "All rights reserved.\n",
      "\n",
      "Copyright (c) 2011-2023, Open source contributors.\n",
      "\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "modification, are permitted provided that the following conditions are met:\n",
      "\n",
      "* Redistributions of source code must retain the above copyright notice, this\n",
      "  list of conditions and the following disclaimer.\n",
      "\n",
      "* Redistributions in binary form must reproduce the above copyright notice,\n",
      "  this list of conditions and the following disclaimer in the documentation\n",
      "  and/or other materials provided with the distribution.\n",
      "\n",
      "* Neither the name of the copyright holder nor the names of its\n",
      "  contributors may be used to endorse or promote products derived from\n",
      "  this software without specific prior written permission.\n",
      "\n",
      "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: numpy, python-dateutil, pytz, tzdata\n",
      "Required-by: altair, bokeh, dask-expr, datasets, datashader, holoviews, hvplot, panel, seaborn, statsmodels, streamlit, xarray\n"
     ]
    }
   ],
   "source": [
    "!pip show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f912f8a1-662c-4e66-88ad-36460c6db98c",
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d1ff64b-53ad-4eca-b846-3fda20085c43",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# File path to data\n",
    "csv_path = ('data/airline_tweets.csv')\n",
    "\n",
    "# Specify the separator\n",
    "tweets = pd.read_csv(csv_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e397ac6a-c2ba-4cce-8700-b36b38026c9d",
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first five rows\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b339f-45cf-465d-931c-05f9096fd510",
   "metadata": {},
   "source": [
    "El marco de datos tiene una fila por tuit. El texto del tuit se muestra en la columna `text`.\n",
    "- `text` (`str`): el texto del tweet.\n",
    "\n",
    "Otros metadatos que nos interesan incluyen: \n",
    "- `airline_sentiment` (`str`): the sentiment of the tweet, etiquetado como as \"neutral,\" \"positive,\" o \"negative.\"\n",
    "- `airline` (`str`): the airline that is tweeted about.\n",
    "- `retweet count` (`int`): como algunos tiempo el tweet fueron retweeteados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c695b-4bd1-4151-9cb9-ef5253eb16df",
   "metadata": {},
   "source": [
    "Echemos un vistazo a algunos de los tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b690daab-7be5-4b8f-8af0-a91fdec4ec4f",
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "tweet 1\n",
      "tweet 2\n",
      "tweet 3\n",
      "      text\n",
      "0  tweet 1\n",
      "1  tweet 2\n",
      "2  tweet 3\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "# Ejemplo de creación de un DataFrame llamado 'tweets'\n",
    "import pandas as pd\n",
    "tweets = pd.DataFrame({\n",
    "    'text': ['tweet 1', 'tweet 2', 'tweet 3']\n",
    "})\n",
    "print(tweets['text'].iloc[0])\n",
    "print(tweets['text'].iloc[1])\n",
    "print(tweets['text'].iloc[2])\n",
    "print(tweets.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc05fa-ad30-4402-ab56-086bcb09a166",
   "metadata": {},
   "source": [
    "🔔 **Pregunta**: Que has notado? Cuáles son las características estilísticas de los tweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3460393-00a6-461c-b02a-9e98f9b5d1af",
   "metadata": {},
   "source": [
    "### Lowercasing\n",
    "\n",
    "Mientras reconocasmos que el uso de mayúsculas y minúsculas de una palabra es informativo, a menudo no trabajamos en contextos en los que podamos utilizar adecuadamente esta información.\n",
    "\n",
    "Mas a menudo, el análisis posterior nosotros realizamos **case-insensitive**. Por ejemplo, en el análisis de frecuencia, queremos tener en cuenta las diversas formas de una misma palabra. Convertir los datos de texto en minúsculas facilita este proceso y simplifica nuestro análisis.\n",
    "\n",
    "Podemos lograr fácilmente la conversión a minúsculas con el método de cadena [`.lower()`](https://docs.python.org/3/library/stdtypes.html#str.lower); see [documentation](https://docs.python.org/3/library/stdtypes.html#string-methods) para mas funciones útiles.\n",
    "\n",
    "Vamos aplicar esto en el sigiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58a95d90-3ef1-4bff-9cfe-d447ed99f252",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas en el DataFrame: 3\n",
      "Índice 108 fuera de rango. El DataFrame solo tiene 3 filas.\n"
     ]
    }
   ],
   "source": [
    "# Verificar cuántas filas tiene el DataFrame / se cambia el código ya que no se define bien \n",
    "print(\"Número de filas en el DataFrame:\", tweets.shape[0])\n",
    "\n",
    "# Verificar si el índice 108 está dentro del rango de las filas\n",
    "if tweets.shape[0] > 108:\n",
    "    first_example = tweets['text'].iloc[108]  # Accede al tweet en el índice 108\n",
    "    print(first_example)\n",
    "else:\n",
    "    print(\"Índice 108 fuera de rango. El DataFrame solo tiene\", tweets.shape[0], \"filas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c66d91c0-6eed-4591-95fc-cd2eae2e0d41",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "==================================================\n",
      "este es un ejemplo de texto\n",
      "==================================================\n",
      "ESTE ES UN EJEMPLO DE TEXTO\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo: asignar un valor a 'first_example'\n",
    "first_example = \"Este es un ejemplo de texto\"\n",
    "\n",
    "# Dado que el codigo anterior no ejecuta ahora el código esta sin errores\n",
    "\n",
    "# Revisar si todos los caracteres están en minúscula \n",
    "print(first_example.islower())  # Devuelve True si todos los caracteres son minúsculas\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "# Convertirlo a minúsculas\n",
    "print(first_example.lower())  # Convierte a minúsculas\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "# Convertirlo a mayúsculas\n",
    "print(first_example.upper())  # Convierte a mayúsculas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0d8c8-bd6c-47ef-b305-09ac61d07d4d",
   "metadata": {},
   "source": [
    "### Eliminar caracteres de espacio en blanco adicionales\n",
    "\n",
    "A veces nosotros podriamos encontrar textos con espacios en blanco extra, such as spaces, tabs, and newline characters, which is particularly common when the text is scrapped from web pages. Before we dive into the details, let's briefly introduce Regular Expressions (regex) and the `re` package. \n",
    "\n",
    "Las expresiones regulares son una forma eficaz de buscar patrones de cadenas específicos en corpus grandes. Su curva de aprendizaje es notablemente pronunciada, pero pueden ser muy eficientes una vez que las dominamos. Muchos paquetes de PNL dependen en gran medida de las expresiones regulares internamente. Los evaluadores de expresiones regulares, como [regex101](https://regex101.com), son herramientas utiles are useful tools tanto en la comprensión como en la creación de expresiones regulares.\n",
    "\n",
    "Nuestro objetivo en este taller no es proporcionar una inmersión profunda (ni siquiera superficial) en las expresiones regulares; en cambio, queremos exponerlo a ellas para que esté mejor preparado para realizar inmersiones profundas en el futuro.\n",
    "\n",
    "El siguiente ejemplo es un poema de William Wordsworth. Como muchos poemas, el texto puede contener saltos de línea adicionales. (i.e., newline characters, `\\n`) que queremos eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1bd73f1-a30f-4269-a05e-47cfff7b496f",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# File path to the poem\n",
    "text_path = 'data/poem_wordsworth.txt'\n",
    "\n",
    "# Read the poem in\n",
    "with open(text_path, 'r') as file:\n",
    "    text = file.read()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a693dd9-9706-40b3-863f-f568020245f7",
   "metadata": {},
   "source": [
    "Como puedes ver, el poema es fomateado como ua cedena continua de textos con los saltos de línea se colocan al final de cada línea, lo que dificulta la lectura. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e78a75a-8e15-4bcb-a416-783aa7f60ef3",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I wandered lonely as a cloud\\n\\n\\nI wandered lonely as a cloud\\nThat floats on high o'er vales and hills,\\nWhen all at once I saw a crowd,\\nA host, of golden daffodils;\\nBeside the lake, beneath the trees,\\nFluttering and dancing in the breeze.\\n\\nContinuous as the stars that shine\\nAnd twinkle on the milky way,\\nThey stretched in never-ending line\\nAlong the margin of a bay:\\nTen thousand saw I at a glance,\\nTossing their heads in sprightly dance.\\n\\nThe waves beside them danced; but they\\nOut-did the sparkling waves in glee:\\nA poet could not but be gay,\\nIn such a jocund company:\\nI gazed—and gazed—but little thought\\nWhat wealth the show to me had brought:\\n\\nFor oft, when on my couch I lie\\nIn vacant or in pensive mood,\\nThey flash upon that inward eye\\nWhich is the bliss of solitude;\\nAnd then my heart with pleasure fills,\\nAnd dances with the daffodils.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cce993-c315-4aaa-87fe-149de8607f65",
   "metadata": {},
   "source": [
    "Una función útil que podemos utilizar para mostrar el poema correctamente es `.splitlines()`. Como sugiere el nombre, divide una secuencia de texto larga en una lista de líneas siempre que haya un carácter de nueva línea.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ddeade7a-065d-49e6-bdd3-87a8ea8f6e6e",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I wandered lonely as a cloud',\n",
       " '',\n",
       " '',\n",
       " 'I wandered lonely as a cloud',\n",
       " \"That floats on high o'er vales and hills,\",\n",
       " 'When all at once I saw a crowd,',\n",
       " 'A host, of golden daffodils;',\n",
       " 'Beside the lake, beneath the trees,',\n",
       " 'Fluttering and dancing in the breeze.',\n",
       " '',\n",
       " 'Continuous as the stars that shine',\n",
       " 'And twinkle on the milky way,',\n",
       " 'They stretched in never-ending line',\n",
       " 'Along the margin of a bay:',\n",
       " 'Ten thousand saw I at a glance,',\n",
       " 'Tossing their heads in sprightly dance.',\n",
       " '',\n",
       " 'The waves beside them danced; but they',\n",
       " 'Out-did the sparkling waves in glee:',\n",
       " 'A poet could not but be gay,',\n",
       " 'In such a jocund company:',\n",
       " 'I gazed—and gazed—but little thought',\n",
       " 'What wealth the show to me had brought:',\n",
       " '',\n",
       " 'For oft, when on my couch I lie',\n",
       " 'In vacant or in pensive mood,',\n",
       " 'They flash upon that inward eye',\n",
       " 'Which is the bliss of solitude;',\n",
       " 'And then my heart with pleasure fills,',\n",
       " 'And dances with the daffodils.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividir la cadena única en una lista de líneas\n",
    "text.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d3825b-0857-44e1-bf6a-d8c7a9032704",
   "metadata": {},
   "source": [
    "Vamos a retornar a nuestros datos tweet para un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53a81ea9-65c4-474a-8530-35393555d1be",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Directorio actual de trabajo: /workspaces/TrabajoFinal\n",
      "Primeras 5 líneas del archivo:\n",
      "I wandered lonely as a cloud\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I wandered lonely as a cloud\n",
      "\n",
      "That floats on high o'er vales and hills,\n",
      "\n",
      "\n",
      "Primeras 5 filas del DataFrame:\n",
      "                                          text\n",
      "0               I wandered lonely as a cloud\\n\n",
      "1                                           \\n\n",
      "2                                           \\n\n",
      "3               I wandered lonely as a cloud\\n\n",
      "4  That floats on high o'er vales and hills,\\n\n",
      "\n",
      "Segundo ejemplo del DataFrame:\n",
      "When all at once I saw a crowd,\n",
      "\n",
      "\n",
      "Texto en minúsculas del segundo ejemplo:\n",
      "when all at once i saw a crowd,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el segundo ejemplo \n",
    "#second_example = tweets['text'][5]\n",
    "#second_example\n",
    "%pip install pandas\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Verificar el directorio actual de trabajo\n",
    "print(f\"Directorio actual de trabajo: {os.getcwd()}\")\n",
    "\n",
    "# Leer el archivo de texto como líneas simples\n",
    "file_path = 'data/poem_wordsworth.txt'  \n",
    "\n",
    "# Leer el archivo línea por línea\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Imprimir las primeras 5 líneas del archivo para verificar su contenido\n",
    "print(\"Primeras 5 líneas del archivo:\")\n",
    "for i in range(min(5, len(lines))):  # Limitar a 5 líneas\n",
    "    print(lines[i])\n",
    "\n",
    "tweets = pd.DataFrame(lines, columns=['text'])\n",
    "\n",
    "# Verificar el contenido cargado\n",
    "print(\"\\nPrimeras 5 filas del DataFrame:\")\n",
    "print(tweets.head())\n",
    "\n",
    "# Ahora, si quieres acceder a un ejemplo específico del DataFrame:\n",
    "second_example = tweets['text'].iloc[5]  # Acceder al segundo ejemplo\n",
    "print(\"\\nSegundo ejemplo del DataFrame:\")\n",
    "print(second_example)\n",
    "\n",
    "# Si deseas realizar otras operaciones en los datos, puedes hacerlo ahora, por ejemplo, convertir el texto a minúsculas:\n",
    "print(\"\\nTexto en minúsculas del segundo ejemplo:\")\n",
    "print(second_example.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef55865-36fd-4c06-a765-530cf3b53096",
   "metadata": {},
   "source": [
    "En este caso, no queremos dividir el tweet en una lista de cadenas. Seguimos esperando una sola cadena de texto, pero queremos eliminar por completo el salto de línea.\n",
    "\n",
    "El método string `.strip()` elimina eficazmente los espacios en ambos extremos del texto. Sin embargo, no funcionará en nuestro ejemplo, ya que el carácter de nueva línea está en el medio de el string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b933503b-4370-4dc4-b287-6dc2f9cdb1d4",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When all at once I saw a crowd,'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solo elimina los espacios en blanco en ambos extremos\n",
    "second_example.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b80b4-804f-460f-a2d5-adbd654902b3",
   "metadata": {},
   "source": [
    "Este es donde la nube regex es realmete útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ceac9714-7053-4b2e-affb-71f8c3d2dcd9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f08d20-ba81-4e48-9e2a-5728148005b3",
   "metadata": {},
   "source": [
    "Ahora, con regex, básicamente, la llamamos para que coincida con un patrón identificado en los datos de texto, y queremos realizar algunas operaciones con la parte coincidente: extraerla, reemplazarla con otra cosa o eliminarla por completo. Por lo tanto, el funcionamiento de las expresiones regulares se puede resumir en los siguientes pasos:\n",
    "\n",
    "- Identificar y escribir los patrones en regex (`r'PATTERN'`)\n",
    "- Escribir el remplazo de los patrones(`'REPLACEMENT'`)\n",
    "- Llamar la función específica regex  (e.g., `re.sub()`)\n",
    "\n",
    "En nuestro ejemplo, el patron que estamos buscando es `\\s`, cuál es el nombre corto en expresión regular para cualquier carácter de espacio en blanco (`\\n` and `\\t` included). También añadimos un cuantificador `+` en el final: `\\s+`. Significa que nos gustaría capturar una o más ocurrencias del carácter de espacio en blanco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1248d227-1149-4014-94a5-c05592a27a7e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Escribir un patron en regex\n",
    "blankspace_pattern = r'\\s+'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc075c2e-1a1d-4393-a3ea-8ad7c118364b",
   "metadata": {},
   "source": [
    "El reemplazo de uno o más espacios en blanco es exactamente un solo espacio, que es el límite canónico de palabras en inglés. Cualquier espacio adicional se reducirá a un solo espacio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c55cb2f1-f4ca-4b79-900c-f65ec303ddac",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ecribir un remplazo para identificación de patrones \n",
    "blankspace_repl = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12e3d1-728a-429b-9c83-4dcc88590bc4",
   "metadata": {},
   "source": [
    "Por último, pongamos todo junto usando la función [`re.sub()`](https://docs.python.org/3.11/library/re.html#re.sub), Lo que significa que queremos sustituir un patrón por un reemplazo. La función acepta tres argumentos: el patrón, el reemplazo y la cadena a la que queremos aplicar la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5249b24b-7111-4569-be29-c40efa5e148e",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este es un ejemplo con espacios extras.\n"
     ]
    }
   ],
   "source": [
    "# Remplazar los espacios en blanco(s) con ' '\n",
    "#clean_text = re.sub(pattern = blankspace_pattern, \n",
    "                    #repl = blankspace_repl, \n",
    "                    #string = second_example)\n",
    "import re  # Asegúrate de importar el módulo 're'\n",
    "\n",
    "# Definir el patrón para los espacios en blanco y el reemplazo\n",
    "blankspace_pattern = r'\\s+'  # Esto busca uno o más espacios en blanco\n",
    "blankspace_repl = ' '  # Esto reemplaza con un solo espacio\n",
    "\n",
    "# Suponiendo que 'second_example' es el texto que quieres limpiar\n",
    "second_example = \"Este es    un  ejemplo   con    espacios   extras.\"\n",
    "\n",
    "# Remplazar los espacios en blanco(s) con ' '\n",
    "clean_text = re.sub(pattern=blankspace_pattern, \n",
    "                    repl=blankspace_repl, \n",
    "                    string=second_example)\n",
    "\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895fbe3-a034-4124-94af-72a528913c51",
   "metadata": {},
   "source": [
    "Ta-da! El carácter de nueva línea ya no está allí."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7087dc0c-5fef-4f1c-8662-7cbc8a978f34",
   "metadata": {},
   "source": [
    "### Eliminar puntuaciones marcadas \n",
    "\n",
    "A veces sólo nos interesa analizar **alphanumeric characters** (i.e., the letters and numbers), en tal caso podríamos querer eliminar los signos de puntuación. \n",
    "\n",
    "El modulo `string` contiene una lista predefinida de puntuaciones marcadas predefinidas. Vamos a imprimir esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70e8502b-b703-45e0-8852-0c3210363440",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# Cargar una lista predefinida de signos de puntuación\n",
    "from string import punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91119c9e-431c-42cb-afea-f7e607698929",
   "metadata": {},
   "source": [
    "En la práctica, para eliminar estos caracteres de puntuación, podemos simplemente iterar sobre el texto y eliminar los caracteres que se encuentran en la lista, como se muestra una función a continuación `remove_punct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "237d868d-339d-4bbe-9a3b-20fa5fbdf231",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    '''Remove punctuation marks in input text'''\n",
    "    \n",
    "    # Select characters not in puncutaion\n",
    "    no_punct = []\n",
    "    for char in text:\n",
    "        if char not in punctuation:\n",
    "            no_punct.append(char)\n",
    "\n",
    "    # Join the characters into a string\n",
    "    text_no_punct = ''.join(no_punct)   \n",
    "    \n",
    "    return text_no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc768b-c2dd-4386-8212-483c4485e4be",
   "metadata": {},
   "source": [
    "Vamos aplicar la función del ejemplo below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7596c465-3d85-4b72-a853-f2151bcd91df",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wandered lonely as a cloud\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I wandered lonely as a cloud\n",
      "\n",
      "That floats on high o'er vales and hills,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el tercer ejemplo\n",
    "#third_example = tweets['text'][20]\n",
    "#print(third_example)\n",
    "#print(f\"{'=' * 50}\")\n",
    "# Abrir y leer el archivo de texto\n",
    "with open('data/poem_wordsworth.txt', 'r', encoding='utf-8') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "# Ver las primeras líneas del archivo para verificar su contenido\n",
    "for line in content[:5]:  # Muestra las primeras 5 líneas\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a4b83-f503-4405-aedd-66bbc088e3e7",
   "metadata": {},
   "source": [
    "Vamos a intentar con otro tweet. Que has notado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b3c2f60-fc92-4326-bad6-5ad04be50476",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wandered lonely as a cloud\n",
      "\n",
      "I wandered lonely as a cloud\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos otro tweet\n",
    "#print(tweets['text'][100])\n",
    "#print(f\"{'=' * 50}\")\n",
    "# Leer el archivo como texto \n",
    "with open('data/poem_wordsworth.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Crear un DataFrame con las líneas leídas\n",
    "tweets = pd.DataFrame(lines, columns=['text'])\n",
    "\n",
    "# Imprimir el primer tweet\n",
    "print(tweets['text'][0])\n",
    "\n",
    "# Aplicar la función remove_punct() al primer tweet\n",
    "import string\n",
    "def remove_punct(text):\n",
    "    return ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "print(remove_punct(tweets['text'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af02ce5-b674-4cb4-8e08-7d7416963f9c",
   "metadata": {},
   "source": [
    "Qué tal el siguiente ejemplo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f8c3947-e6b8-42fe-8a58-15e4b6c60005",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weve got quite a bit of punctuation here dont we Python DLab'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimimos el texto con contracción \n",
    "contraction_text = \"We've got quite a bit of punctuation here, don't we?!? #Python @D-Lab.\"\n",
    "\n",
    "# Aplicar las funciones\n",
    "remove_punct(contraction_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62574c66-db3f-4500-9c3b-cea2f3eb2a30",
   "metadata": {},
   "source": [
    "⚠️ **Advertencia:** en algún caso, nosotros queremos remover la tokenización de puntuaciones marcadas **after** , cual discutiriamos en minutos. Esto nos diria que el orden de preprocesamiento **order** es un asunto de importancia!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6b85e-58e7-4f56-9b4a-b60c85b394ba",
   "metadata": {},
   "source": [
    "## 🥊 Reto 1: Preprocesamiento con multiples pasos \n",
    "\n",
    "Entonces ahora hemos aprendido algunas operaciones de preprocesamiento. ¡Combinémoslas en una función! Esta función te resultará útil si trabajas con datos de texto en inglés confusos y quieres preprocesarlos con una sola función.\n",
    "\n",
    "A continuación se muestra el ejemplo de datos de texto para el desafío 1. Escribe una función para:\n",
    "- Convertir el texto en minúsculas\n",
    "- Eliminar signos de puntuación\n",
    "- Eliminar espacios en blanco adicionales\n",
    "\n",
    "Puedes reciclar el código que usamos anteriormente.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "deb10cba-239e-4856-b56d-7d5eb850c9b9",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This is a text file that has some extra blankspace at the start and end. Blankspace is a catch-all term for spaces, tabs, newlines, and a bunch of other things that computers distinguish but to us all look like spaces, tabs and newlines.\n",
      "\n",
      "\n",
      "The Python method called \"strip\" only catches blankspace at the start and end of a string. But it won't catch it in       the middle,\t\tfor example,\n",
      "\n",
      "in this sentence.\t\tOnce again, regular expressions will\n",
      "\n",
      "help\t\tus    with this.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "challenge1_path = 'data/example1.txt'\n",
    "\n",
    "with open(challenge1_path, 'r') as file:\n",
    "    challenge1 = file.read()\n",
    "    \n",
    "print(challenge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2480823-65dd-4f52-a7b3-6d9b10d87912",
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # Step 1: Lowercase\n",
    "    text = ...\n",
    "\n",
    "    # Step 2: Use remove_punct to remove punctuation marks\n",
    "    text = ...\n",
    "\n",
    "    # Step 3: Remove extra whitespace characters\n",
    "    text = ...\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dc603506-0adb-45d7-bb6f-62958c054fdd",
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descomentar la aplicación sobre la función del reto 1 \n",
    "clean_text(challenge1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c159cb-8eaa-4c30-b8ff-38a712d2bb0f",
   "metadata": {},
   "source": [
    "## Procesos de Tareas específicas\n",
    "\n",
    "Ahora que comprendemos las operaciones comunes de preprocesamiento, aún quedan algunas operaciones adicionales por considerar. Nuestros datos de texto podrían requerir una mayor normalización según el idioma, la fuente y el contenido de los datos.\n",
    "\n",
    "Por ejemplo, si trabajamos con documentos financieros, podríamos querer estandarizar los símbolos monetarios convirtiéndolos en dígitos. En nuestros datos de tuits, existen numerosos hashtags y URL. Estos pueden reemplazarse con marcadores de posición para simplificar el análisis posterior.s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2936cea-74e9-40c2-bfbe-6ba8129330de",
   "metadata": {},
   "source": [
    "### 🎬 **Demo**: Eliminar Hashtags y URLs \n",
    "\n",
    "Aunque las URL, los hashtags y los números son informativos por sí mismos, a menudo no nos importa su significado exacto.\n",
    "\n",
    "Si bien podríamos eliminarlos por completo, suele ser informativo saber que existe una URL o un hashtag. En la práctica, reemplazamos las URL y los hashtags individuales con un \"símbolo\" que preserva la existencia de estas estructuras en el texto. Lo habitual es usar las cadenas \"URL\" y \"HASHTAG\".\n",
    "\n",
    "Dado que estos tipos de texto suelen seguir una estructura regular, son un ejemplo adecuado para el uso de expresiones regulares. Apliquemos estos patrones a los datos de los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "03c0dc37-a013-4f0a-b72f-a1f64dc6c1bd",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Along the margin of a bay:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir un ejemplo de tweet \n",
    "url_tweet = tweets['text'][13]\n",
    "print(url_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ef61bea-ea11-468d-8176-a2f63659d204",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Along the margin of a bay:\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL \n",
    "url_pattern = r'(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])'\n",
    "url_repl = ' URL '\n",
    "re.sub(url_pattern, url_repl, url_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea8e0f2a-460e-4088-aa89-dc2a8bc6f7fe",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Along the margin of a bay:\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hashtag\n",
    "hashtag_pattern = r'(?:^|\\s)[＃#]{1}(\\w+)'\n",
    "hashtag_repl = ' HASHTAG '\n",
    "re.sub(hashtag_pattern, hashtag_repl, url_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7943ed9-70de-4f4a-b1bb-b2896d05e618",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "1. A tutorial introducing the tokenization scheme in BERT: [The huggingface NLP course on wordpiece tokenization](https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt)\n",
    "2. A specific example of \"failure\" in tokenization: [Weaknesses of wordpiece tokenization: Findings from the front lines of NLP at VMware.](https://medium.com/@rickbattle/weaknesses-of-wordpiece-tokenization-eb20e37fec99)\n",
    "3. How does BERT decide boundaries between subtokens: [Subword tokenization in BERT](https://tinkerd.net/blog/machine-learning/bert-tokenization/#subword-tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0812a7-f033-46ed-bc7b-67109c369e6c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## ❗ Puntos claves \n",
    "\n",
    "* Preprocesamiento incluido en los ultimos pasos, algunos de estos son mas comunes para datos de textos independientes, y algunas son tareas especificas. \n",
    "* Ambas `nltk` y `spaCy` podría utilizarse para tokenizar y eliminar palabras vacías. Esta última opción es más eficaz para proporcionar diversas anotaciones lingüísticas. \n",
    "* La tokenización funciona de manera diferente en BERT, que a menudo implica dividir una palabra completa en subpalabras. \n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
