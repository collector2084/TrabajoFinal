{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e7ea21-6437-48e8-a9e4-3bdc05f709c9",
   "metadata": {},
   "source": [
    "# Analisis de texto en Python: Preprocesamiento\n",
    "\n",
    "* * * \n",
    "\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "### Objetivos de aprendizaje \n",
    "    \n",
    "* Aprender pasos comunes para preprocesamiento de datos de texto, tan bien como especificar operaciones para preprocesamiento de datos de Twitter.\n",
    "* Conocer los paquetes NPL comunmente usado y acoplarlos.\n",
    "* Entender tokenizadores, y como cambiar desde la llegada de los grandes modelos de lenguaje.\n",
    "</div>\n",
    "\n",
    "### Icons Used in This Notebook\n",
    "üîî **Pregunta**: Una pregunta rapida para ayudar a entender que esta sucediendo.<br>\n",
    "ü•ä **Reto**: Ejercicios interactivos. Trabajaremos a traves de esto en el taller!<br>\n",
    "‚ö†Ô∏è **Advertencia:** Aviso sobre cosas complicadas o errores comunes.<br>\n",
    "üé¨ **Demo**: Mostrando algo m√°s avanzado: para que sepas para qu√© se puede usar Python!<br> \n",
    "\n",
    "### Secciones\n",
    "1. [Preprocessing](#section1)\n",
    "2. [Tokenization](#section2)\n",
    "\n",
    "En esta seccion de tres parte del taller, aprenderemos la construccion de bloques para ejecutar anlisis de texto en Python. Estas tecnicas se encuentran en el dominio de Procesamiento de Lenguaje Natural (NLP). NLP es un campo que se ocupa con identificacion y extrayendo patrones de lenguaje, ante todo escribiendo textos. A lo largo de la serie de talleres, interactuaremos con paquetes para ejecutar analisis de texto: empezando desde metodos de cadena simple hasta paquetes especificos  NLP, tal como `nltk`, `spaCy`, y mas recientes sobre Modelos de Lenguaje Grande (`BERT`).\n",
    "\n",
    "Ahora, Instalemos estos paquetes correctamente ante de introducirnos en la materia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d442e4c7-e926-493d-a64e-516616ad915a",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Uncomment the following lines to install packages/model\n",
    "# %pip install NLTK\n",
    "# %pip install transformers\n",
    "# %pip install spaCy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b8f8e-4e69-426e-a202-ec48b325e89a",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "\n",
    "# Preprocesamiento\n",
    "\n",
    "En la parte 1 de este taller, Direccionaremos el primer paso de analisis de texto. Nuestra meta es convertir la fila, datos de texto desordenados en un formato consistente. Este proceso es a menudo llamado **preprocesamiento**, **limpieza de texto**, o **normalizaci√≥n de texto**.\n",
    "\n",
    "Notaras que al final del procesamiento,nuestro sto es aun en formato que nosostros podemos leer y entender. En la parte 2 y 3, comenzaremos nuestra incursi√≥n en la conversi√≥n de datos de texto en una representaci√≥n num√©rica, un formato que las computadoras pueden manejar m√°s f√°cilmente. \n",
    "\n",
    "üîî **Pregunta**: Vamos a pausar un momento para reflexionar sobre **sus** previas experiencias trabajando sobre texto de datos. \n",
    "- Cual es el formato de los datos de texto con los que has interactuado (plain text, CSV, or XML)?\n",
    "- De donde viene (structured corpus, scraped from the web, survey data)?\n",
    "- Esta desordenado (i.e., is the data formatted consistently)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35911a-3b3f-4a48-a7d1-9882aab04851",
   "metadata": {},
   "source": [
    "## Procesos Comunes\n",
    "\n",
    "Preprocesamiento no es aldo que podamos lograr con una simple linea de c√≥digo. Nosotros a menudo empezamos por familiarizarnos nosotros mismo con los datos, y en el camino, obtenemos una comprensi√≥n m√°s clara de la granularidad del preprocesamiento que queremos aplicar.\n",
    "\n",
    "Inicialmente, comenzamos aplicando un conjunto de procesos com√∫nmente utilizados para limpiar los datos. Estas operaciones so alteran facilmente la forma o el significado de los datos; sirven como un procedimiento estandarizado para remodelar los datos en un formato consistente.\n",
    "\n",
    "La siguientes procesos, por ejemplo, son comunmente aplicados para procesos de textos en ingles de varios generos. Estas operaciones pueden  estar siendo usadas para funciones integrles en Python, tal como metodos`string`, y expresiones regulares. \n",
    "- El texto en minuscula\n",
    "- Remover puntuaciones marcadas \n",
    "- Remover caracteres de espacio en blanco\n",
    "- Remover palabras en stop \n",
    "\n",
    "Despu√©s al iniciar el procesamiento, nosotros debemos cambiar para realizar procesos de tareas especificas, cuyos detalles a menudo dependen de la tarea posterior que queremos realizar y de la naturaleza de los datos de texto (i.e., its stylistic and linguistic features).  \n",
    "\n",
    "Antes de adentrarnos en estas operaciones, echemos un vistazo a nuestros datos!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5d7350-9a1e-4db9-b828-a87fe1676d8d",
   "metadata": {},
   "source": [
    "### Importar el texto de datos\n",
    "\n",
    "El texto de datos, podemos estar trabajando con un archivo CSV. Contiene tuits sobre aerol√≠neas estadounidenses, eliminados desde febrero de 2015. \n",
    "\n",
    "Vamos a leer el archivo `airline_tweets.csv` dentro del dataframe con `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7228677e-001b-4484-b85d-9d4218a1469d",
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pandas\n",
      "Version: 2.2.2\n",
      "Summary: Powerful data structures for data analysis, time series, and statistics\n",
      "Home-page: https://pandas.pydata.org\n",
      "Author: \n",
      "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
      "License: BSD 3-Clause License\n",
      "\n",
      "Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
      "All rights reserved.\n",
      "\n",
      "Copyright (c) 2011-2023, Open source contributors.\n",
      "\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "modification, are permitted provided that the following conditions are met:\n",
      "\n",
      "* Redistributions of source code must retain the above copyright notice, this\n",
      "  list of conditions and the following disclaimer.\n",
      "\n",
      "* Redistributions in binary form must reproduce the above copyright notice,\n",
      "  this list of conditions and the following disclaimer in the documentation\n",
      "  and/or other materials provided with the distribution.\n",
      "\n",
      "* Neither the name of the copyright holder nor the names of its\n",
      "  contributors may be used to endorse or promote products derived from\n",
      "  this software without specific prior written permission.\n",
      "\n",
      "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: numpy, python-dateutil, pytz, tzdata\n",
      "Required-by: altair, bokeh, dask-expr, datasets, datashader, holoviews, hvplot, panel, seaborn, statsmodels, streamlit, xarray\n"
     ]
    }
   ],
   "source": [
    "!pip show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f912f8a1-662c-4e66-88ad-36460c6db98c",
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d1ff64b-53ad-4eca-b846-3fda20085c43",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# File path to data\n",
    "csv_path = ('data/airline_tweets.csv')\n",
    "\n",
    "# Specify the separator\n",
    "tweets = pd.read_csv(csv_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e397ac6a-c2ba-4cce-8700-b36b38026c9d",
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first five rows\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b339f-45cf-465d-931c-05f9096fd510",
   "metadata": {},
   "source": [
    "El marco de datos tiene una fila por tuit. El texto del tuit se muestra en la columna `text`.\n",
    "- `text` (`str`): el texto del tweet.\n",
    "\n",
    "Otros metadatos que nos interesan incluyen: \n",
    "- `airline_sentiment` (`str`): the sentiment of the tweet, etiquetado como as \"neutral,\" \"positive,\" o \"negative.\"\n",
    "- `airline` (`str`): the airline that is tweeted about.\n",
    "- `retweet count` (`int`): como algunos tiempo el tweet fueron retweeteados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c695b-4bd1-4151-9cb9-ef5253eb16df",
   "metadata": {},
   "source": [
    "Echemos un vistazo a algunos de los tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b690daab-7be5-4b8f-8af0-a91fdec4ec4f",
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "tweet 1\n",
      "tweet 2\n",
      "tweet 3\n",
      "      text\n",
      "0  tweet 1\n",
      "1  tweet 2\n",
      "2  tweet 3\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "# Ejemplo de creaci√≥n de un DataFrame llamado 'tweets'\n",
    "import pandas as pd\n",
    "tweets = pd.DataFrame({\n",
    "    'text': ['tweet 1', 'tweet 2', 'tweet 3']\n",
    "})\n",
    "print(tweets['text'].iloc[0])\n",
    "print(tweets['text'].iloc[1])\n",
    "print(tweets['text'].iloc[2])\n",
    "print(tweets.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc05fa-ad30-4402-ab56-086bcb09a166",
   "metadata": {},
   "source": [
    "üîî **Pregunta**: Que has notado? Cu√°les son las caracter√≠sticas estil√≠sticas de los tweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3460393-00a6-461c-b02a-9e98f9b5d1af",
   "metadata": {},
   "source": [
    "### Lowercasing\n",
    "\n",
    "Mientras reconocasmos que el uso de may√∫sculas y min√∫sculas de una palabra es informativo, a menudo no trabajamos en contextos en los que podamos utilizar adecuadamente esta informaci√≥n.\n",
    "\n",
    "Mas a menudo, el an√°lisis posterior nosotros realizamos **case-insensitive**. Por ejemplo, en el an√°lisis de frecuencia, queremos tener en cuenta las diversas formas de una misma palabra. Convertir los datos de texto en min√∫sculas facilita este proceso y simplifica nuestro an√°lisis.\n",
    "\n",
    "Podemos lograr f√°cilmente la conversi√≥n a min√∫sculas con el m√©todo de cadena [`.lower()`](https://docs.python.org/3/library/stdtypes.html#str.lower); see [documentation](https://docs.python.org/3/library/stdtypes.html#string-methods) para mas funciones √∫tiles.\n",
    "\n",
    "Vamos aplicar esto en el sigiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58a95d90-3ef1-4bff-9cfe-d447ed99f252",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de filas en el DataFrame: 3\n",
      "√çndice 108 fuera de rango. El DataFrame solo tiene 3 filas.\n"
     ]
    }
   ],
   "source": [
    "# Verificar cu√°ntas filas tiene el DataFrame / se cambia el c√≥digo ya que no se define bien \n",
    "print(\"N√∫mero de filas en el DataFrame:\", tweets.shape[0])\n",
    "\n",
    "# Verificar si el √≠ndice 108 est√° dentro del rango de las filas\n",
    "if tweets.shape[0] > 108:\n",
    "    first_example = tweets['text'].iloc[108]  # Accede al tweet en el √≠ndice 108\n",
    "    print(first_example)\n",
    "else:\n",
    "    print(\"√çndice 108 fuera de rango. El DataFrame solo tiene\", tweets.shape[0], \"filas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c66d91c0-6eed-4591-95fc-cd2eae2e0d41",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "==================================================\n",
      "este es un ejemplo de texto\n",
      "==================================================\n",
      "ESTE ES UN EJEMPLO DE TEXTO\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo: asignar un valor a 'first_example'\n",
    "first_example = \"Este es un ejemplo de texto\"\n",
    "\n",
    "# Dado que el codigo anterior no ejecuta ahora el c√≥digo esta sin errores\n",
    "\n",
    "# Revisar si todos los caracteres est√°n en min√∫scula \n",
    "print(first_example.islower())  # Devuelve True si todos los caracteres son min√∫sculas\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "# Convertirlo a min√∫sculas\n",
    "print(first_example.lower())  # Convierte a min√∫sculas\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "# Convertirlo a may√∫sculas\n",
    "print(first_example.upper())  # Convierte a may√∫sculas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0d8c8-bd6c-47ef-b305-09ac61d07d4d",
   "metadata": {},
   "source": [
    "### Eliminar caracteres de espacio en blanco adicionales\n",
    "\n",
    "A veces nosotros podriamos encontrar textos con espacios en blanco extra, such as spaces, tabs, and newline characters, which is particularly common when the text is scrapped from web pages. Before we dive into the details, let's briefly introduce Regular Expressions (regex) and the `re` package. \n",
    "\n",
    "Las expresiones regulares son una forma eficaz de buscar patrones de cadenas espec√≠ficos en corpus grandes. Su curva de aprendizaje es notablemente pronunciada, pero pueden ser muy eficientes una vez que las dominamos. Muchos paquetes de PNL dependen en gran medida de las expresiones regulares internamente. Los evaluadores de expresiones regulares, como [regex101](https://regex101.com), son herramientas utiles are useful tools tanto en la comprensi√≥n como en la creaci√≥n de expresiones regulares.\n",
    "\n",
    "Nuestro objetivo en este taller no es proporcionar una inmersi√≥n profunda (ni siquiera superficial) en las expresiones regulares; en cambio, queremos exponerlo a ellas para que est√© mejor preparado para realizar inmersiones profundas en el futuro.\n",
    "\n",
    "El siguiente ejemplo es un poema de William Wordsworth. Como muchos poemas, el texto puede contener saltos de l√≠nea adicionales. (i.e., newline characters, `\\n`) que queremos eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1bd73f1-a30f-4269-a05e-47cfff7b496f",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# File path to the poem\n",
    "text_path = 'data/poem_wordsworth.txt'\n",
    "\n",
    "# Read the poem in\n",
    "with open(text_path, 'r') as file:\n",
    "    text = file.read()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a693dd9-9706-40b3-863f-f568020245f7",
   "metadata": {},
   "source": [
    "Como puedes ver, el poema es fomateado como ua cedena continua de textos con los saltos de l√≠nea se colocan al final de cada l√≠nea, lo que dificulta la lectura. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e78a75a-8e15-4bcb-a416-783aa7f60ef3",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I wandered lonely as a cloud\\n\\n\\nI wandered lonely as a cloud\\nThat floats on high o'er vales and hills,\\nWhen all at once I saw a crowd,\\nA host, of golden daffodils;\\nBeside the lake, beneath the trees,\\nFluttering and dancing in the breeze.\\n\\nContinuous as the stars that shine\\nAnd twinkle on the milky way,\\nThey stretched in never-ending line\\nAlong the margin of a bay:\\nTen thousand saw I at a glance,\\nTossing their heads in sprightly dance.\\n\\nThe waves beside them danced; but they\\nOut-did the sparkling waves in glee:\\nA poet could not but be gay,\\nIn such a jocund company:\\nI gazed‚Äîand gazed‚Äîbut little thought\\nWhat wealth the show to me had brought:\\n\\nFor oft, when on my couch I lie\\nIn vacant or in pensive mood,\\nThey flash upon that inward eye\\nWhich is the bliss of solitude;\\nAnd then my heart with pleasure fills,\\nAnd dances with the daffodils.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cce993-c315-4aaa-87fe-149de8607f65",
   "metadata": {},
   "source": [
    "Una funci√≥n √∫til que podemos utilizar para mostrar el poema correctamente es `.splitlines()`. Como sugiere el nombre, divide una secuencia de texto larga en una lista de l√≠neas siempre que haya un car√°cter de nueva l√≠nea.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ddeade7a-065d-49e6-bdd3-87a8ea8f6e6e",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I wandered lonely as a cloud',\n",
       " '',\n",
       " '',\n",
       " 'I wandered lonely as a cloud',\n",
       " \"That floats on high o'er vales and hills,\",\n",
       " 'When all at once I saw a crowd,',\n",
       " 'A host, of golden daffodils;',\n",
       " 'Beside the lake, beneath the trees,',\n",
       " 'Fluttering and dancing in the breeze.',\n",
       " '',\n",
       " 'Continuous as the stars that shine',\n",
       " 'And twinkle on the milky way,',\n",
       " 'They stretched in never-ending line',\n",
       " 'Along the margin of a bay:',\n",
       " 'Ten thousand saw I at a glance,',\n",
       " 'Tossing their heads in sprightly dance.',\n",
       " '',\n",
       " 'The waves beside them danced; but they',\n",
       " 'Out-did the sparkling waves in glee:',\n",
       " 'A poet could not but be gay,',\n",
       " 'In such a jocund company:',\n",
       " 'I gazed‚Äîand gazed‚Äîbut little thought',\n",
       " 'What wealth the show to me had brought:',\n",
       " '',\n",
       " 'For oft, when on my couch I lie',\n",
       " 'In vacant or in pensive mood,',\n",
       " 'They flash upon that inward eye',\n",
       " 'Which is the bliss of solitude;',\n",
       " 'And then my heart with pleasure fills,',\n",
       " 'And dances with the daffodils.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividir la cadena √∫nica en una lista de l√≠neas\n",
    "text.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d3825b-0857-44e1-bf6a-d8c7a9032704",
   "metadata": {},
   "source": [
    "Vamos a retornar a nuestros datos tweet para un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53a81ea9-65c4-474a-8530-35393555d1be",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Directorio actual de trabajo: /workspaces/TrabajoFinal\n",
      "Primeras 5 l√≠neas del archivo:\n",
      "I wandered lonely as a cloud\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I wandered lonely as a cloud\n",
      "\n",
      "That floats on high o'er vales and hills,\n",
      "\n",
      "\n",
      "Primeras 5 filas del DataFrame:\n",
      "                                          text\n",
      "0               I wandered lonely as a cloud\\n\n",
      "1                                           \\n\n",
      "2                                           \\n\n",
      "3               I wandered lonely as a cloud\\n\n",
      "4  That floats on high o'er vales and hills,\\n\n",
      "\n",
      "Segundo ejemplo del DataFrame:\n",
      "When all at once I saw a crowd,\n",
      "\n",
      "\n",
      "Texto en min√∫sculas del segundo ejemplo:\n",
      "when all at once i saw a crowd,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el segundo ejemplo \n",
    "#second_example = tweets['text'][5]\n",
    "#second_example\n",
    "%pip install pandas\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Verificar el directorio actual de trabajo\n",
    "print(f\"Directorio actual de trabajo: {os.getcwd()}\")\n",
    "\n",
    "# Leer el archivo de texto como l√≠neas simples\n",
    "file_path = 'data/poem_wordsworth.txt'  \n",
    "\n",
    "# Leer el archivo l√≠nea por l√≠nea\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Imprimir las primeras 5 l√≠neas del archivo para verificar su contenido\n",
    "print(\"Primeras 5 l√≠neas del archivo:\")\n",
    "for i in range(min(5, len(lines))):  # Limitar a 5 l√≠neas\n",
    "    print(lines[i])\n",
    "\n",
    "tweets = pd.DataFrame(lines, columns=['text'])\n",
    "\n",
    "# Verificar el contenido cargado\n",
    "print(\"\\nPrimeras 5 filas del DataFrame:\")\n",
    "print(tweets.head())\n",
    "\n",
    "# Ahora, si quieres acceder a un ejemplo espec√≠fico del DataFrame:\n",
    "second_example = tweets['text'].iloc[5]  # Acceder al segundo ejemplo\n",
    "print(\"\\nSegundo ejemplo del DataFrame:\")\n",
    "print(second_example)\n",
    "\n",
    "# Si deseas realizar otras operaciones en los datos, puedes hacerlo ahora, por ejemplo, convertir el texto a min√∫sculas:\n",
    "print(\"\\nTexto en min√∫sculas del segundo ejemplo:\")\n",
    "print(second_example.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef55865-36fd-4c06-a765-530cf3b53096",
   "metadata": {},
   "source": [
    "En este caso, no queremos dividir el tweet en una lista de cadenas. Seguimos esperando una sola cadena de texto, pero queremos eliminar por completo el salto de l√≠nea.\n",
    "\n",
    "El m√©todo string `.strip()` elimina eficazmente los espacios en ambos extremos del texto. Sin embargo, no funcionar√° en nuestro ejemplo, ya que el car√°cter de nueva l√≠nea est√° en el medio de el string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b933503b-4370-4dc4-b287-6dc2f9cdb1d4",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When all at once I saw a crowd,'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solo elimina los espacios en blanco en ambos extremos\n",
    "second_example.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b80b4-804f-460f-a2d5-adbd654902b3",
   "metadata": {},
   "source": [
    "Este es donde la nube regex es realmete √∫til."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ceac9714-7053-4b2e-affb-71f8c3d2dcd9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f08d20-ba81-4e48-9e2a-5728148005b3",
   "metadata": {},
   "source": [
    "Ahora, con regex, b√°sicamente, la llamamos para que coincida con un patr√≥n identificado en los datos de texto, y queremos realizar algunas operaciones con la parte coincidente: extraerla, reemplazarla con otra cosa o eliminarla por completo. Por lo tanto, el funcionamiento de las expresiones regulares se puede resumir en los siguientes pasos:\n",
    "\n",
    "- Identificar y escribir los patrones en regex (`r'PATTERN'`)\n",
    "- Escribir el remplazo de los patrones(`'REPLACEMENT'`)\n",
    "- Llamar la funci√≥n espec√≠fica regex  (e.g., `re.sub()`)\n",
    "\n",
    "En nuestro ejemplo, el patron que estamos buscando es `\\s`, cu√°l es el nombre corto en expresi√≥n regular para cualquier car√°cter de espacio en blanco (`\\n` and `\\t` included). Tambi√©n a√±adimos un cuantificador `+` en el final: `\\s+`. Significa que nos gustar√≠a capturar una o m√°s ocurrencias del car√°cter de espacio en blanco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1248d227-1149-4014-94a5-c05592a27a7e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Escribir un patron en regex\n",
    "blankspace_pattern = r'\\s+'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc075c2e-1a1d-4393-a3ea-8ad7c118364b",
   "metadata": {},
   "source": [
    "El reemplazo de uno o m√°s espacios en blanco es exactamente un solo espacio, que es el l√≠mite can√≥nico de palabras en ingl√©s. Cualquier espacio adicional se reducir√° a un solo espacio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c55cb2f1-f4ca-4b79-900c-f65ec303ddac",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ecribir un remplazo para identificaci√≥n de patrones \n",
    "blankspace_repl = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12e3d1-728a-429b-9c83-4dcc88590bc4",
   "metadata": {},
   "source": [
    "Por √∫ltimo, pongamos todo junto usando la funci√≥n [`re.sub()`](https://docs.python.org/3.11/library/re.html#re.sub), Lo que significa que queremos sustituir un patr√≥n por un reemplazo. La funci√≥n acepta tres argumentos: el patr√≥n, el reemplazo y la cadena a la que queremos aplicar la funci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5249b24b-7111-4569-be29-c40efa5e148e",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este es un ejemplo con espacios extras.\n"
     ]
    }
   ],
   "source": [
    "# Remplazar los espacios en blanco(s) con ' '\n",
    "#clean_text = re.sub(pattern = blankspace_pattern, \n",
    "                    #repl = blankspace_repl, \n",
    "                    #string = second_example)\n",
    "import re  # Aseg√∫rate de importar el m√≥dulo 're'\n",
    "\n",
    "# Definir el patr√≥n para los espacios en blanco y el reemplazo\n",
    "blankspace_pattern = r'\\s+'  # Esto busca uno o m√°s espacios en blanco\n",
    "blankspace_repl = ' '  # Esto reemplaza con un solo espacio\n",
    "\n",
    "# Suponiendo que 'second_example' es el texto que quieres limpiar\n",
    "second_example = \"Este es    un  ejemplo   con    espacios   extras.\"\n",
    "\n",
    "# Remplazar los espacios en blanco(s) con ' '\n",
    "clean_text = re.sub(pattern=blankspace_pattern, \n",
    "                    repl=blankspace_repl, \n",
    "                    string=second_example)\n",
    "\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895fbe3-a034-4124-94af-72a528913c51",
   "metadata": {},
   "source": [
    "Ta-da! El car√°cter de nueva l√≠nea ya no est√° all√≠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7087dc0c-5fef-4f1c-8662-7cbc8a978f34",
   "metadata": {},
   "source": [
    "### Eliminar puntuaciones marcadas \n",
    "\n",
    "A veces s√≥lo nos interesa analizar **alphanumeric characters** (i.e., the letters and numbers), en tal caso podr√≠amos querer eliminar los signos de puntuaci√≥n. \n",
    "\n",
    "El modulo `string` contiene una lista predefinida de puntuaciones marcadas predefinidas. Vamos a imprimir esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70e8502b-b703-45e0-8852-0c3210363440",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# Cargar una lista predefinida de signos de puntuaci√≥n\n",
    "from string import punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91119c9e-431c-42cb-afea-f7e607698929",
   "metadata": {},
   "source": [
    "En la pr√°ctica, para eliminar estos caracteres de puntuaci√≥n, podemos simplemente iterar sobre el texto y eliminar los caracteres que se encuentran en la lista, como se muestra una funci√≥n a continuaci√≥n `remove_punct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "237d868d-339d-4bbe-9a3b-20fa5fbdf231",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    '''Remove punctuation marks in input text'''\n",
    "    \n",
    "    # Select characters not in puncutaion\n",
    "    no_punct = []\n",
    "    for char in text:\n",
    "        if char not in punctuation:\n",
    "            no_punct.append(char)\n",
    "\n",
    "    # Join the characters into a string\n",
    "    text_no_punct = ''.join(no_punct)   \n",
    "    \n",
    "    return text_no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc768b-c2dd-4386-8212-483c4485e4be",
   "metadata": {},
   "source": [
    "Vamos aplicar la funci√≥n del ejemplo below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7596c465-3d85-4b72-a853-f2151bcd91df",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wandered lonely as a cloud\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I wandered lonely as a cloud\n",
      "\n",
      "That floats on high o'er vales and hills,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el tercer ejemplo\n",
    "#third_example = tweets['text'][20]\n",
    "#print(third_example)\n",
    "#print(f\"{'=' * 50}\")\n",
    "# Abrir y leer el archivo de texto\n",
    "with open('data/poem_wordsworth.txt', 'r', encoding='utf-8') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "# Ver las primeras l√≠neas del archivo para verificar su contenido\n",
    "for line in content[:5]:  # Muestra las primeras 5 l√≠neas\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a4b83-f503-4405-aedd-66bbc088e3e7",
   "metadata": {},
   "source": [
    "Vamos a intentar con otro tweet. Que has notado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b3c2f60-fc92-4326-bad6-5ad04be50476",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wandered lonely as a cloud\n",
      "\n",
      "I wandered lonely as a cloud\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos otro tweet\n",
    "#print(tweets['text'][100])\n",
    "#print(f\"{'=' * 50}\")\n",
    "# Leer el archivo como texto \n",
    "with open('data/poem_wordsworth.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Crear un DataFrame con las l√≠neas le√≠das\n",
    "tweets = pd.DataFrame(lines, columns=['text'])\n",
    "\n",
    "# Imprimir el primer tweet\n",
    "print(tweets['text'][0])\n",
    "\n",
    "# Aplicar la funci√≥n remove_punct() al primer tweet\n",
    "import string\n",
    "def remove_punct(text):\n",
    "    return ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "print(remove_punct(tweets['text'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af02ce5-b674-4cb4-8e08-7d7416963f9c",
   "metadata": {},
   "source": [
    "Qu√© tal el siguiente ejemplo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f8c3947-e6b8-42fe-8a58-15e4b6c60005",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weve got quite a bit of punctuation here dont we Python DLab'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimimos el texto con contracci√≥n \n",
    "contraction_text = \"We've got quite a bit of punctuation here, don't we?!? #Python @D-Lab.\"\n",
    "\n",
    "# Aplicar las funciones\n",
    "remove_punct(contraction_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62574c66-db3f-4500-9c3b-cea2f3eb2a30",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Advertencia:** en alg√∫n caso, nosotros queremos remover la tokenizaci√≥n de puntuaciones marcadas **after** , cual discutiriamos en minutos. Esto nos diria que el orden de preprocesamiento **order** es un asunto de importancia!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6b85e-58e7-4f56-9b4a-b60c85b394ba",
   "metadata": {},
   "source": [
    "## ü•ä Reto 1: Preprocesamiento con multiples pasos \n",
    "\n",
    "Entonces ahora hemos aprendido algunas operaciones de preprocesamiento. ¬°Combin√©moslas en una funci√≥n! Esta funci√≥n te resultar√° √∫til si trabajas con datos de texto en ingl√©s confusos y quieres preprocesarlos con una sola funci√≥n.\n",
    "\n",
    "A continuaci√≥n se muestra el ejemplo de datos de texto para el desaf√≠o 1. Escribe una funci√≥n para:\n",
    "- Convertir el texto en min√∫sculas\n",
    "- Eliminar signos de puntuaci√≥n\n",
    "- Eliminar espacios en blanco adicionales\n",
    "\n",
    "Puedes reciclar el c√≥digo que usamos anteriormente.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "deb10cba-239e-4856-b56d-7d5eb850c9b9",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This is a text file that has some extra blankspace at the start and end. Blankspace is a catch-all term for spaces, tabs, newlines, and a bunch of other things that computers distinguish but to us all look like spaces, tabs and newlines.\n",
      "\n",
      "\n",
      "The Python method called \"strip\" only catches blankspace at the start and end of a string. But it won't catch it in       the middle,\t\tfor example,\n",
      "\n",
      "in this sentence.\t\tOnce again, regular expressions will\n",
      "\n",
      "help\t\tus    with this.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "challenge1_path = 'data/example1.txt'\n",
    "\n",
    "with open(challenge1_path, 'r') as file:\n",
    "    challenge1 = file.read()\n",
    "    \n",
    "print(challenge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2480823-65dd-4f52-a7b3-6d9b10d87912",
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # Step 1: Lowercase\n",
    "    text = ...\n",
    "\n",
    "    # Step 2: Use remove_punct to remove punctuation marks\n",
    "    text = ...\n",
    "\n",
    "    # Step 3: Remove extra whitespace characters\n",
    "    text = ...\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dc603506-0adb-45d7-bb6f-62958c054fdd",
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descomentar la aplicaci√≥n sobre la funci√≥n del reto 1 \n",
    "clean_text(challenge1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c159cb-8eaa-4c30-b8ff-38a712d2bb0f",
   "metadata": {},
   "source": [
    "## Procesos de Tareas espec√≠ficas\n",
    "\n",
    "Ahora que comprendemos las operaciones comunes de preprocesamiento, a√∫n quedan algunas operaciones adicionales por considerar. Nuestros datos de texto podr√≠an requerir una mayor normalizaci√≥n seg√∫n el idioma, la fuente y el contenido de los datos.\n",
    "\n",
    "Por ejemplo, si trabajamos con documentos financieros, podr√≠amos querer estandarizar los s√≠mbolos monetarios convirti√©ndolos en d√≠gitos. En nuestros datos de tuits, existen numerosos hashtags y URL. Estos pueden reemplazarse con marcadores de posici√≥n para simplificar el an√°lisis posterior.s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2936cea-74e9-40c2-bfbe-6ba8129330de",
   "metadata": {},
   "source": [
    "### üé¨ **Demo**: Eliminar Hashtags y URLs \n",
    "\n",
    "Aunque las URL, los hashtags y los n√∫meros son informativos por s√≠ mismos, a menudo no nos importa su significado exacto.\n",
    "\n",
    "Si bien podr√≠amos eliminarlos por completo, suele ser informativo saber que existe una URL o un hashtag. En la pr√°ctica, reemplazamos las URL y los hashtags individuales con un \"s√≠mbolo\" que preserva la existencia de estas estructuras en el texto. Lo habitual es usar las cadenas \"URL\" y \"HASHTAG\".\n",
    "\n",
    "Dado que estos tipos de texto suelen seguir una estructura regular, son un ejemplo adecuado para el uso de expresiones regulares. Apliquemos estos patrones a los datos de los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "03c0dc37-a013-4f0a-b72f-a1f64dc6c1bd",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Along the margin of a bay:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir un ejemplo de tweet \n",
    "url_tweet = tweets['text'][13]\n",
    "print(url_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ef61bea-ea11-468d-8176-a2f63659d204",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Along the margin of a bay:\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL \n",
    "url_pattern = r'(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])'\n",
    "url_repl = ' URL '\n",
    "re.sub(url_pattern, url_repl, url_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea8e0f2a-460e-4088-aa89-dc2a8bc6f7fe",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Along the margin of a bay:\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hashtag\n",
    "hashtag_pattern = r'(?:^|\\s)[ÔºÉ#]{1}(\\w+)'\n",
    "hashtag_repl = ' HASHTAG '\n",
    "re.sub(hashtag_pattern, hashtag_repl, url_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7943ed9-70de-4f4a-b1bb-b2896d05e618",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "1. A tutorial introducing the tokenization scheme in BERT: [The huggingface NLP course on wordpiece tokenization](https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt)\n",
    "2. A specific example of \"failure\" in tokenization: [Weaknesses of wordpiece tokenization: Findings from the front lines of NLP at VMware.](https://medium.com/@rickbattle/weaknesses-of-wordpiece-tokenization-eb20e37fec99)\n",
    "3. How does BERT decide boundaries between subtokens: [Subword tokenization in BERT](https://tinkerd.net/blog/machine-learning/bert-tokenization/#subword-tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0812a7-f033-46ed-bc7b-67109c369e6c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## ‚ùó Puntos claves \n",
    "\n",
    "* Preprocesamiento incluido en los ultimos pasos, algunos de estos son mas comunes para datos de textos independientes, y algunas son tareas especificas. \n",
    "* Ambas `nltk` y `spaCy` podr√≠a utilizarse para tokenizar y eliminar palabras vac√≠as. Esta √∫ltima opci√≥n es m√°s eficaz para proporcionar diversas anotaciones ling√º√≠sticas. \n",
    "* La tokenizaci√≥n funciona de manera diferente en BERT, que a menudo implica dividir una palabra completa en subpalabras. \n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
